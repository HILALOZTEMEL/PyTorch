{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14.The Sequential module.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCNdwLfvyW9EZflPeWw/dG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HILALOZTEMEL/PyTorch/blob/main/14_The_Sequential_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AlexNet - declaring the modules**"
      ],
      "metadata": {
        "id": "hpKJTJ2kRSCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "eRsw1CT_Tofz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2zdIyh_oQ3Rr"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(self,num_classes=1000):\n",
        "    super(AlexNet, self).__init()\n",
        "    self.conv1=nn.Conv2d(3,64,kernel_size=11,stride=4,padding=2)\n",
        "    self.relu=nn.ReLU(inplace=True)\n",
        "    self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "    self.conv2=nn.Conv2d(64,192,kernel_size = 5 , padding = 2)\n",
        "    self.conv3=nn.Conv2d(192,384,kernel_size = 3 , padding = 1)\n",
        "    self.conv4=nn.Conv2d(384,256,kernel_size = 3 , padding = 1)\n",
        "    self.conv5=nn.Conv2d(256,256,kernel_size = 3 , padding = 1)\n",
        "    self.avgpool=nn.AdaptiveAvgPool2d((6,6))\n",
        "    self.fc1=nn.Linear(256*6*6,4096)\n",
        "    self.fc2=nn.Linear(4096,4096)\n",
        "    self.fc3=nn.Linear(4096,num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AlexNet-forward()methods**"
      ],
      "metadata": {
        "id": "XpqvAel_UPyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def forward(self, x):        \n",
        "    x = self.relu(self.conv1(x))        \n",
        "    x = self.maxpool(x)        \n",
        "    x = self.relu(self.conv2(x))        \n",
        "    x = self.maxpool(x)        \n",
        "    x = self.relu(self.conv3(x))        \n",
        "    x = self.relu(self.conv4(x))        \n",
        "    x = self.relu(self.conv5(x))        \n",
        "    x = self.maxpool(x)        \n",
        "    x = self.avgpool(x)        \n",
        "    x = x.view(x.size(0), 256 * 6 * 6)        \n",
        "    x = self.relu(self.fc1(x))        \n",
        "    x = self.relu(self.fc2(x))\n",
        "    return self.fc3(x)\n",
        "    \n",
        "net = AlexNet()        \n"
      ],
      "metadata": {
        "id": "U_ZBd-NzUGv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The sequential module-declaring the modules**"
      ],
      "metadata": {
        "id": "hxH0fvM0UuWb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEQUENTİAL MODEL az kod ile aynı sinir ağını oluşturmamızı sağlar.sıralı modul olarak adlandırılır ve ileri beslemeli ağlar için(akışın tek yönde gitiiği çok kullanışlıdır).\n",
        "\n",
        "Bu modulu kulllanarak ağınızı bölümlere ayırabilirsiniz."
      ],
      "metadata": {
        "id": "c6apJDO7Vbcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classAlexNet(nn.Module):\n",
        "  def__init__(self, num_classes=1000):        \n",
        "    super(AlexNet, self).__init__()        \n",
        "    self.features = nn.Sequential(            \n",
        "        nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), \n",
        "        nn.ReLU(inplace=True),            \n",
        "        nn.MaxPool2d(kernel_size=3, stride=2), \n",
        "        nn.Conv2d(64, 192, kernel_size=5, padding=2),            \n",
        "        nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2),            \n",
        "        nn.Conv2d(192, 384, kernel_size=3, padding=1), nn.ReLU(inplace=True),           \n",
        "        nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),            \n",
        "        nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),            \n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),)        \n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((6, 6))        \n",
        "    self.classifier = nn.Sequential(            \n",
        "        nn.Dropout(), nn.Linear(256 * 6 * 6, 4096), \n",
        "        nn.ReLU(inplace=True),                     \n",
        "        nn.Dropout(), \n",
        "        nn.Linear(4096, 4096), \n",
        "        nn.ReLU(inplace=True), \n",
        "        \n",
        "        nn.Linear(4096, num_classes),)           \n"
      ],
      "metadata": {
        "id": "_3vhLDYaUw8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thesequentialmodule-forward()method**"
      ],
      "metadata": {
        "id": "r1LdC_bpVDgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def forward(self, x):        \n",
        "    x = self.features(x)        \n",
        "    x = self.avgpool(x)        \n",
        "    x = x.view(x.size(0), 256 * 6 * 6)       \n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "QbRdn8mhVHmO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}